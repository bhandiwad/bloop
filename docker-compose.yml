version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    container_name: bloop-postgres
    environment:
      POSTGRES_DB: bloop
      POSTGRES_USER: bloop
      POSTGRES_PASSWORD: bloop_dev_password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    # SECURITY: Ports NOT exposed to host in production
    # Uncomment for local database access if needed
    # ports:
    #   - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U bloop"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - bloop-network

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: bloop-redis
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    # SECURITY: Ports NOT exposed to host in production
    # Uncomment for local Redis access if needed
    # ports:
    #   - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    restart: unless-stopped
    networks:
      - bloop-network

  # Bloop Application
  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: bloop-app
    environment:
      NODE_ENV: production
      PORT: 5000
      DATABASE_URL: postgresql://bloop:bloop_dev_password@postgres:5432/bloop
      REDIS_URL: redis://redis:6379
      # CRITICAL: Set SESSION_SECRET before deploying to production
      # Generate with: openssl rand -hex 32
      # Or use .env file / Docker secrets
      SESSION_SECRET: ${SESSION_SECRET:-INSECURE_CHANGE_THIS_IN_PRODUCTION}
      # Optional: OpenAI API if you want AI-generated answers
      # AI_INTEGRATIONS_OPENAI_API_KEY: ${AI_INTEGRATIONS_OPENAI_API_KEY}
      # AI_INTEGRATIONS_OPENAI_BASE_URL: ${AI_INTEGRATIONS_OPENAI_BASE_URL}
    ports:
      - "5000:5000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - bloop-network
    # Initialize database on first run
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        set -e  # Exit on error
        
        # Run database migrations
        if command -v psql >/dev/null 2>&1; then
          echo "Running database migrations..."
          # Capture migration output to check for errors
          MIGRATION_OUTPUT=$(PGPASSWORD=bloop_dev_password psql -h postgres -U bloop -d bloop -f /app/migrations/001_initial_schema.sql 2>&1)
          MIGRATION_STATUS=$?
          
          # Check if migration failed with non-"already exists" errors
          if [ $MIGRATION_STATUS -ne 0 ]; then
            # Check if error is just "already exists" (safe to ignore)
            if echo "$MIGRATION_OUTPUT" | grep -qi "already exists"; then
              echo "Migration already applied (tables exist) - continuing"
            else
              echo "FATAL: Migration failed with errors:"
              echo "$MIGRATION_OUTPUT"
              exit 1
            fi
          else
            echo "Migration completed successfully"
          fi
        else
          echo "WARNING: psql not found - skipping migrations"
        fi
        
        # Start the application
        exec node dist/index.js
    # For development, you can volume mount the code
    # volumes:
    #   - .:/app
    #   - /app/node_modules

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local

networks:
  bloop-network:
    driver: bridge
